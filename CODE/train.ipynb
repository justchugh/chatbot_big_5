{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "1QVKjYiou4TA"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\shwet\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk \n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "CZhlgyPXu4TF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataframe = pd.read_csv('newanswers.csv',index_col=False,header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "6lhd9VSEu4TH"
      },
      "outputs": [],
      "source": [
        "x_train = dataframe[0].values\n",
        "y_train = dataframe[1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "yOGxd3JWu4TH"
      },
      "outputs": [],
      "source": [
        "x_test = ['I keep care of not leaving my belongings anywhere',\n",
        "            'I try to not leave things anywhere',\n",
        "            \"I don't agree about this\",\n",
        "            'I sometimes leave things around',\n",
        "            'I always leave things around']\n",
        "y_test = [5, 4, 2, 4, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x_test = ['Sometimes','I always think about others','Sometimes I am','I feel stressed out all the time','I agree that I have a rich vocabulary']\n",
        "\n",
        "# y_test = [3,5,3,4,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Iif1Z1i6u4TI"
      },
      "outputs": [],
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "eRuFi5wgu4TJ"
      },
      "outputs": [],
      "source": [
        "def changecontractions(text):\n",
        "    words = text.split()\n",
        "    for i in range(len(words)):\n",
        "        if words[i] in contractions.keys():\n",
        "            words[i] = contractions[words[i]]\n",
        "            \n",
        "    words = \" \".join(words)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "stopword = nltk.corpus.stopwords.words('english') \n",
        "print(stopword)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "gdajJyx_u4TK"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    wn = nltk.WordNetLemmatizer()\n",
        "    stopword = nltk.corpus.stopwords.words('english') \n",
        "    text = changecontractions(text)        \n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lower = [word.lower() for word in tokens]   \n",
        "    stopword = nltk.corpus.stopwords.words('english') \n",
        "    for i in stopword:\n",
        "        if i == 'no' or i =='not' or i == 'nor':\n",
        "            stopword.remove(i) \n",
        "    no_stopwords = [word for word in lower if word not in stopword]\n",
        "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
        "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
        "    clean_text = lemm_text\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "FAfTMTwIu4TK"
      },
      "outputs": [],
      "source": [
        "def newpre(df):\n",
        "    xnew = []\n",
        "    for i in df:\n",
        "        xnew.append(\" \".join(i))\n",
        "    return xnew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "LAEC48gPu4TL"
      },
      "outputs": [],
      "source": [
        "x_clean = [clean(i) for i in x_train]\n",
        "xnewclean = newpre(x_clean)\n",
        "# print(xnewclean)\n",
        "x_testc = [clean(i) for i in x_test]\n",
        "xtestnewclean = newpre(x_testc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "0U_24VOHu4TM"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "x_vec = cv.fit_transform(xnewclean).toarray()\n",
        "# print(cv.get_feature_names())\n",
        "xt_vec = cv.transform(xtestnewclean).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "bEbMd3nKu4TM"
      },
      "outputs": [],
      "source": [
        "def feature(df):\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    cv = CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "    x_vec = cv.fit_transform(df).toarray()\n",
        "    # print(cv.get_feature_names())\n",
        "    return x_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "YOXQYGO9u4TM"
      },
      "outputs": [],
      "source": [
        "x_vect = feature(xnewclean)\n",
        "# print(x_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "MVydadmou4TN"
      },
      "outputs": [],
      "source": [
        "def predictposneg(df,train,test,test_val):\n",
        "    from sklearn.naive_bayes import MultinomialNB\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    mn = MultinomialNB()\n",
        "    mn.fit(df,train)\n",
        "    y_pred = mn.predict(test)\n",
        "    filename = 'finalized_model.sav'\n",
        "    pickle.dump(mn, open(filename, 'wb'))\n",
        "    acc = accuracy_score(test_val,y_pred)\n",
        "    return y_pred,acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "MjY5on-sx5j2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 4 4 4 1] 0.8\n"
          ]
        }
      ],
      "source": [
        "y_pred,acc = predictposneg(x_vect,y_train,xt_vec,y_test)\n",
        "print(y_pred,acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq0iOLjGu4TN",
        "outputId": "c3ce0ade-64cc-4919-850a-7717a33b3f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 4 4 4 1]\n",
            "[5, 4, 2, 4, 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "GjvS5RZSu4TO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_list(csvname):\n",
        "    df = pd.read_csv(csvname)\n",
        "    questions = list(df['questions'])\n",
        "    factors = list(df['factors'])\n",
        "    direction = list(df['direction'])\n",
        "    return questions,factors,direction\n",
        "\n",
        "def evaluate(scores):\n",
        "    questions,factors,direction = get_list(\"big-five.csv\")\n",
        "    l = len(scores)\n",
        "    questions,factors,direction = questions[:l],factors[:l],direction[:l]\n",
        "    uni_fac = set(factors)\n",
        "    fac={}\n",
        "    for i in uni_fac:\n",
        "        fac[i]=[]\n",
        "    for i in range(l):\n",
        "        if(direction[i]=='-'):\n",
        "            scores[i]=-scores[i]\n",
        "        fac[factors[i]].append(scores[i])\n",
        "    for i in fac.keys():\n",
        "        fac[i]=sum(fac[i])\n",
        "    return fac\n",
        "\n",
        "def get_personality(scores,length):\n",
        "    df = pd.read_csv(\"personality.csv\")\n",
        "    mins,maxs=length/len(scores.keys()),length\n",
        "    mid = (mins+maxs)//2\n",
        "    response=[]\n",
        "    for i in scores.keys():\n",
        "        if(scores[i]<mid):\n",
        "            res=list(df[(df['factor']==i) & (df['score']=='L')]['response'])\n",
        "            response.append(res[0])\n",
        "        else:\n",
        "            res=list(df[(df['factor']==i) & (df['score']=='H')]['response'])\n",
        "            response.append(res[0])\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "ZJDMUNs1u4TO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check your evaluation below\n",
            "\n",
            "You might prefer working independently on projects and achieve your best work working alone. You might tend to struggle with collaborating or discussing ideas with team members.You might tend to be more forceful with their opinions. You can be headstrong in their ideas. You might need to work on being more sympathetic to others' views and try to ensure you listen to other team members’ perspectives more.You might tend to be much more flexible in your approach to work. Structures isn't always required for you, and you don’t rely heavily on being organized. This might make it challenging for such you to meet strict deadlines or manage your time efficiently.You can work in a more stable, predictable way, despite high-pressure situations. You will also have a more positive outlook in terms of challenging projects and are generally more optimistic. Staying calm where others might become stressed in the workplace comes naturally to you.You typically prefer methodical and logical approaches to their work. You are less likely to embrace change, preferring to maintain the status quo in terms of your work style.\n",
            "I hope you agree\n"
          ]
        }
      ],
      "source": [
        "scores=[5,1,2,5,2,1,5,4,2,3,4,3,1,5,2]\n",
        "fac = evaluate(scores)\n",
        "print(\"Check your evaluation below\\n\")\n",
        "response = get_personality(fac,len(scores))\n",
        "print(''.join(response))\n",
        "print(\"I hope you agree\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8auFpxHvvwuK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3aaef2b754b576a1e077e008914502732999be3bd1de93577b5e5d41d61e163d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
