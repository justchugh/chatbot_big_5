{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7768eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "dataframe = pd.read_csv('newanswers.csv', index_col=False, header=None)\n",
    "x_train = dataframe[0].values\n",
    "y_train = dataframe[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6807b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "x_test = ['I keep care of not leaving my belongings anywhere',\n",
    "           'I try to not leave things anywhere',\n",
    "           \"I don't agree about this\",\n",
    "           'I sometimes leave things around',\n",
    "           'I always leave things around']\n",
    "y_test = [5, 4, 2, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contractions dictionary\n",
    "contractions = { 'ain't': 'am not', 'aren't': 'are not', \"can't\": 'cannot', 'couldn't': 'could not', 'didn't': 'did not', 'doesn't': 'does not', 'don't': 'do not', 'hadn't': 'had not', 'hasn't': 'has not', 'haven't': 'have not', 'he'd': 'he would', 'he'll': 'he will', 'he's': 'he is', 'i'd': 'I would', 'i'll': 'I will', 'i'm': 'I am', 'i've': 'I have', 'isn't': 'is not', 'it'd': 'it would', 'it'll': 'it will', 'it's': 'it is', 'let's': 'let us', 'ma'am': 'madam', 'mightn't': 'might not', 'mustn't': 'must not', 'shan't': 'shall not', \"she'd\": 'she would', \"she'll\": 'she will', \"she's\": 'she is', \"should've\": 'should have', \"shouldn't\": 'should not', \"so've\": 'so have', \"that's\": 'that is', \"there's\": 'there is', \"they'd\": 'they would', \"they'll\": 'they will', \"they're\": 'they are', \"they've\": 'they have', \"wasn't\": 'was not', \"we'd\": 'we would', \"we'll\": 'we will', \"we're\": 'we are', \"we've\": 'we have', \"weren't\": 'were not', \"what's\": 'what is', \"where's\": 'where is', \"who's\": 'who is', \"won't\": 'will not', \"would've\": 'would have', \"wouldn't\": 'would not', \"y'all\": 'you all', \"you'd\": 'you would', \"you'll\": 'you will', \"you're\": 'you are', \"you've\": 'you have'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change contractions\n",
    "def changecontractions(text):\n",
    "    words = text.split()\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in contractions.keys():\n",
    "            words[i] = contractions[words[i]]\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d66628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    text = changecontractions(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lower = [word.lower() for word in tokens]\n",
    "    for i in stopword:\n",
    "        if i == 'no' or i == 'not' or i == 'nor':\n",
    "            stopword.remove(i)\n",
    "    no_stopwords = [word for word in lower if word not in stopword]\n",
    "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
    "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
    "    clean_text = lemm_text\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42069366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the training data\n",
    "x_clean = [clean(i) for i in x_train]\n",
    "def newpre(df):\n",
    "    xnew = []\n",
    "    for i in df:\n",
    "        xnew.append(' '.join(i))\n",
    "    return xnew\n",
    "xnewclean = newpre(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112958fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the test data\n",
    "x_testc = [clean(i) for i in x_test]\n",
    "xtestnewclean = newpre(x_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a36bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "x_vec = cv.fit_transform(xnewclean).toarray()\n",
    "xt_vec = cv.transform(xtestnewclean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def feature(df):\n",
    "    cv = CountVectorizer(ngram_range=(1,2))\n",
    "    x_vec = cv.fit_transform(df).toarray()\n",
    "    return x_vec\n",
    "x_vect = feature(xnewclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict using MultinomialNB\n",
    "def predictposneg(df, train, test, test_val):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    mn = MultinomialNB()\n",
    "    mn.fit(df, train)\n",
    "    y_pred = mn.predict(test)\n",
    "    filename = 'finalized_model.sav'\n",
    "    pickle.dump(mn, open(filename, 'wb'))\n",
    "    acc = accuracy_score(test_val, y_pred)\n",
    "    return y_pred, acc\n",
    "y_pred, acc = predictposneg(x_vect, y_train, xt_vec, y_test)\n",
    "print(y_pred, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get list from CSV\n",
    "def get_list(csvname):\n",
    "    df = pd.read_csv(csvname)\n",
    "    questions = list(df['questions'])\n",
    "    factors = list(df['factors'])\n",
    "    direction = list(df['direction'])\n",
    "    return questions, factors, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f746a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate scores\n",
    "def evaluate(scores):\n",
    "    questions, factors, direction = get_list('big-five.csv')\n",
    "    l = len(scores)\n",
    "    questions, factors, direction = questions[:l], factors[:l], direction[:l]\n",
    "    uni_fac = set(factors)\n",
    "    fac = {}\n",
    "    for i in uni_fac:\n",
    "        fac[i] = []\n",
    "    for i in range(l):\n",
    "        if direction[i] == '-':\n",
    "            scores[i] = -scores[i]\n",
    "        fac[factors[i]].append(scores[i])\n",
    "    for i in fac.keys():\n",
    "        fac[i] = sum(fac[i])\n",
    "    return fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get personality\n",
    "def get_personality(scores, length):\n",
    "    df = pd.read_csv('personality.csv')\n",
    "    mins, maxs = length / len(scores.keys()), length\n",
    "    mid = (mins + maxs) // 2\n",
    "    response = []\n",
    "    for i in scores.keys():\n",
    "        if scores[i] < mid:\n",
    "            res = list(df[(df['factor'] == i) & (df['score'] == 'L')]['response'])\n",
    "            response.append(res[0])\n",
    "        else:\n",
    "            res = list(df[(df['factor'] == i) & (df['score'] == 'H')]['response'])\n",
    "            response.append(res[0])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and get personality scores\n",
    "scores = [5, 1, 2, 5, 2, 1, 5, 4, 2, 3, 4, 3, 1, 5, 2]\n",
    "fac = evaluate(scores)\n",
    "print('Check your evaluation below\\n')\n",
    "response = get_personality(fac, len(scores))\n",
    "print(''.join(response))\n",
    "print('I hope you agree')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
