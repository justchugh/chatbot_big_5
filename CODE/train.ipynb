{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c895dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean data\n",
    "dataframe = pd.read_csv('newanswers.csv', index_col=False, header=None)\n",
    "x_train = dataframe[0].values\n",
    "y_train = dataframe[1].values\n",
    "x_test = ['I keep care of not leaving my belongings anywhere', 'I try to not leave things anywhere', \"I don't agree about this\", 'I sometimes leave things around', 'I always leave things around']\n",
    "y_test = [5, 4, 2, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e874736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords and punctuation\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = set(\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5aa3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lower = [word.lower() for word in tokens]\n",
    "    no_stopwords = [word for word in lower if word not in stopwords]\n",
    "    no_punctuation = [word for word in no_stopwords if word not in punctuation]\n",
    "    lemm_text = [wn.lemmatize(word) for word in no_punctuation]\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65342105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def newpre(df):\n",
    "    xnew = []\n",
    "    for i in df:\n",
    "        xnew.append(' '.join(i))\n",
    "    return xnew\n",
    "x_clean = [clean(i) for i in x_train]\n",
    "xnewclean = newpre(x_clean)\n",
    "x_testc = [clean(i) for i in x_test]\n",
    "extestnewclean = newpre(x_testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text\n",
    "cv = TfidfVectorizer(ngram_range=(1,2))\n",
    "x_vec = cv.fit_transform(xnewclean).toarray()\n",
    "xt_vec = cv.transform(extestnewclean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f77d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict using Naive Bayes\n",
    "def predictposneg(df, train, test, test_val):\n",
    "    mn = MultinomialNB()\n",
    "    mn.fit(df, train)\n",
    "    y_pred = mn.predict(test)\n",
    "    filename = 'finalized_model.sav'\n",
    "    pickle.dump(mn, open(filename, 'wb'))\n",
    "    acc = accuracy_score(test_val, y_pred)\n",
    "    return y_pred, acc\n",
    "y_pred, acc = predictposneg(x_vec, y_train, xt_vec, y_test)\n",
    "print(y_pred, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example scores\n",
    "scores = [5, 1, 2, 5, 2, 1, 5, 4, 2, 3, 4, 3, 1, 5, 2]\n",
    "fac = {'Openness': 12, 'Conscientiousness': 14, 'Extraversion': 10, 'Agreeableness': 8, 'Neuroticism': 11}\n",
    "print('Check your evaluation below')\n",
    "print('Openness:', fac['Openness'])\n",
    "print('Conscientiousness:', fac['Conscientiousness'])\n",
    "print('Extraversion:', fac['Extraversion'])\n",
    "print('Agreeableness:', fac['Agreeableness'])\n",
    "print('Neuroticism:', fac['Neuroticism'])\n",
    "print('I hope you agree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72503603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Results\n",
    "results = {'y_test': y_test, 'y_pred': y_pred}\n",
    "df_results = pd.DataFrame(results)\n",
    "sns.heatmap(df_results.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "def save_model(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "save_model(mn, 'naive_bayes_model.pkl')\n",
    "print('Model saved as naive_bayes_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f89958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "model = load_model('naive_bayes_model.pkl')\n",
    "print('Model loaded from naive_bayes_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675dab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional data analysis\n",
    "accuracy = [acc]\n",
    "plt.plot(accuracy)\n",
    "plt.title('Model Accuracy Over Time')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
